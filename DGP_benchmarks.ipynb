{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca08450a-8615-4677-b4ca-c011d082ffb8",
   "metadata": {},
   "source": [
    "# DGP benchmarks\n",
    "\n",
    "Deep Gaussian Process (DGP) benchmarks for 'Kernels with Latent Gaussian Processes for Non-stationary Regression' paper.\n",
    "Here we train and evaluate:\n",
    "- 2 layer DGP\n",
    "- 3 layer DGP\n",
    "- 5 layer DGP\n",
    "\n",
    "Doubly Stochastic Variational Inference is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd342ae-a6a4-4b0a-be85-bebb2fd186b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%set_env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "import gpytorch\n",
    "from gpytorch.means import ConstantMean, LinearMean\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from gpytorch.variational import VariationalStrategy, CholeskyVariationalDistribution\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.models import ApproximateGP, GP\n",
    "from gpytorch.mlls import VariationalELBO, AddedLossTerm\n",
    "from gpytorch.likelihoods import GaussianLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f03c76c-9930-4b3d-8ddd-38d4da375ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models.deep_gps import DeepGPLayer, DeepGP\n",
    "from gpytorch.mlls import DeepApproximateMLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb6f5f6b-c407-4038-bc03-90e337456f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "from math import floor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc9a884-ea07-4c03-994a-57666c3a59bb",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16e502ec-1a8a-4af4-87d8-71dc8565077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "smoke_test = ('CI' in os.environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "703a7fc5-daee-47c5-96a2-06e9d52b2bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('khyber_2000_2010_tp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "063622ad-31ea-4cbb-acd2-413819a8e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if smoke_test:  # this is for running the notebook in our testing framework\n",
    "    X, y = torch.randn(1000, 3), torch.randn(1000)\n",
    "else:\n",
    "    data = torch.Tensor(data_df.values)\n",
    "    X = data[:, 1:-1]\n",
    "    X = X - X.min(0)[0]\n",
    "    X = 2 * (X / X.max(0)[0]) - 1\n",
    "    y = data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6a5f82b-8688-4dfc-ab81-67f05f0a36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = int(floor(0.8 * len(X)))\n",
    "train_x = X[:train_n, :].contiguous()\n",
    "train_y = y[:train_n].contiguous()\n",
    "\n",
    "test_x = X[train_n:, :].contiguous()\n",
    "test_y = y[train_n:].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "422310fa-e7fb-4906-b09a-3485332495e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    train_x, train_y, test_x, test_y = train_x.cuda(), train_y.cuda(), test_x.cuda(), test_y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b959f1bb-e067-43b2-8604-4e466335fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3ee54b-5641-460d-8ece-59096de41025",
   "metadata": {},
   "source": [
    "## Define GP Layer\n",
    "\n",
    "Creates layer class with number of inducing points, the variational distribution and the variational strategy.We also define the covariance and mean functions of the layer. The foward method returns the prior to be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c0468a3-0e02-4929-a110-56f5578d81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDeepGPHiddenLayer(DeepGPLayer):\n",
    "    def __init__(self, input_dims, output_dims, num_inducing=128, mean_type='constant'):\n",
    "        if output_dims is None:\n",
    "            inducing_points = torch.randn(num_inducing, input_dims)\n",
    "            batch_shape = torch.Size([])\n",
    "        else:\n",
    "            inducing_points = torch.randn(output_dims, num_inducing, input_dims)\n",
    "            batch_shape = torch.Size([output_dims])\n",
    "\n",
    "        variational_distribution = CholeskyVariationalDistribution(\n",
    "            num_inducing_points=num_inducing,\n",
    "            batch_shape=batch_shape\n",
    "        )\n",
    "\n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self,\n",
    "            inducing_points,\n",
    "            variational_distribution,\n",
    "            learn_inducing_locations=True\n",
    "        )\n",
    "\n",
    "        super(ToyDeepGPHiddenLayer, self).__init__(variational_strategy, input_dims, output_dims)\n",
    "\n",
    "        if mean_type == 'constant':\n",
    "            self.mean_module = ConstantMean(batch_shape=batch_shape)\n",
    "        else:\n",
    "            self.mean_module = LinearMean(input_dims)\n",
    "        self.covar_module = ScaleKernel(\n",
    "            RBFKernel(batch_shape=batch_shape, ard_num_dims=input_dims),\n",
    "            batch_shape=batch_shape, ard_num_dims=None\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "    def __call__(self, x, *other_inputs, **kwargs):\n",
    "        \"\"\"\n",
    "        Overriding __call__ isn't strictly necessary, but it lets us add concatenation based skip connections\n",
    "        easily. For example, hidden_layer2(hidden_layer1_outputs, inputs) will pass the concatenation of the first\n",
    "        hidden layer's outputs and the input data to hidden_layer2.\n",
    "        \"\"\"\n",
    "        if len(other_inputs):\n",
    "            if isinstance(x, gpytorch.distributions.MultitaskMultivariateNormal):\n",
    "                x = x.rsample()\n",
    "\n",
    "            processed_inputs = [\n",
    "                inp.unsqueeze(0).expand(gpytorch.settings.num_likelihood_samples.value(), *inp.shape)\n",
    "                for inp in other_inputs\n",
    "            ]\n",
    "\n",
    "            x = torch.cat([x] + processed_inputs, dim=-1)\n",
    "\n",
    "        return super().__call__(x, are_samples=bool(len(other_inputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f19b72-e1d7-45c8-a698-b87f498e8560",
   "metadata": {},
   "source": [
    "## Building the deep GP\n",
    "\n",
    "Here we create a module whose forward is simply responsible for forwarding through the various layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90972e24-d5c2-4ddd-89eb-bc8b8c161093",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output_dims = 2 if smoke_test else 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5db120a-0e96-4ce4-8bc4-5b957b098dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepGP2(DeepGP):\n",
    "    def __init__(self, train_x_shape):\n",
    "        hidden_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims=train_x_shape[-1],\n",
    "            output_dims=num_output_dims,\n",
    "            mean_type='linear',\n",
    "        )\n",
    "\n",
    "        last_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims=hidden_layer.output_dims,\n",
    "            output_dims=None,\n",
    "            mean_type='constant',\n",
    "        )\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.last_layer = last_layer\n",
    "        self.likelihood = GaussianLikelihood()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        hidden_rep1 = self.hidden_layer(inputs)\n",
    "        output = self.last_layer(hidden_rep1)\n",
    "        return output\n",
    "\n",
    "    def predict(self, test_loader):\n",
    "        with torch.no_grad():\n",
    "            mus = []\n",
    "            variances = []\n",
    "            lls = []\n",
    "            for x_batch, y_batch in test_loader:\n",
    "                preds = self.likelihood(self(x_batch))\n",
    "                mus.append(preds.mean)\n",
    "                variances.append(preds.variance)\n",
    "                lls.append(model.likelihood.log_marginal(y_batch, model(x_batch)))\n",
    "\n",
    "        return torch.cat(mus, dim=-1), torch.cat(variances, dim=-1), torch.cat(lls, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e23cb670-1120-4f89-924e-1b6770fc95c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepGP3(DeepGP):\n",
    "    def __init__(self, train_x_shape):\n",
    "        first_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims=train_x_shape[-1],\n",
    "            output_dims=num_output_dims,\n",
    "            mean_type='linear',\n",
    "        )\n",
    "        \n",
    "        middle_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims= num_output_dims,\n",
    "            output_dims= num_output_dims,\n",
    "            mean_type='linear',\n",
    "        )\n",
    "\n",
    "        last_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims=middle_layer.output_dims,\n",
    "            output_dims=None,\n",
    "            mean_type='constant',\n",
    "        )\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.first_layer = first_layer\n",
    "        self.middle_layer = middle_layer\n",
    "        self.last_layer = last_layer\n",
    "        self.likelihood = GaussianLikelihood()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        hidden_rep1 = self.first_layer(inputs)\n",
    "        hidden_rep2 = self.middle_layer(hidden_rep1)\n",
    "        output = self.last_layer(hidden_rep2)\n",
    "        return output\n",
    "\n",
    "    def predict(self, test_loader):\n",
    "        with torch.no_grad():\n",
    "            mus = []\n",
    "            variances = []\n",
    "            lls = []\n",
    "            for x_batch, y_batch in test_loader:\n",
    "                preds = self.likelihood(self(x_batch))\n",
    "                mus.append(preds.mean)\n",
    "                variances.append(preds.variance)\n",
    "                lls.append(model.likelihood.log_marginal(y_batch, model(x_batch)))\n",
    "\n",
    "        return torch.cat(mus, dim=-1), torch.cat(variances, dim=-1), torch.cat(lls, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee424b3a-ead0-476e-8538-92bc732344b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepGP5(DeepGP):\n",
    "    def __init__(self, train_x_shape):\n",
    "        first_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims=train_x_shape[-1],\n",
    "            output_dims=num_output_dims,\n",
    "            mean_type='linear',\n",
    "        )\n",
    "        \n",
    "        middle_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims= num_output_dims,\n",
    "            output_dims= num_output_dims,\n",
    "            mean_type='linear',\n",
    "        )\n",
    "\n",
    "        last_layer = ToyDeepGPHiddenLayer(\n",
    "            input_dims=middle_layer.output_dims,\n",
    "            output_dims=None,\n",
    "            mean_type='constant',\n",
    "        )\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.first_layer = first_layer\n",
    "        self.middle_layer = middle_layer\n",
    "        self.last_layer = last_layer\n",
    "        self.likelihood = GaussianLikelihood()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        hidden_rep1 = self.first_layer(inputs)\n",
    "        hidden_rep2 = self.middle_layer(hidden_rep1)\n",
    "        hidden_rep3 = self.middle_layer(hidden_rep2)\n",
    "        hidden_rep4 = self.middle_layer(hidden_rep3)\n",
    "        output = self.last_layer(hidden_rep4)\n",
    "        return output\n",
    "\n",
    "\n",
    "    def predict(self, test_loader):\n",
    "        with torch.no_grad():\n",
    "            mus = []\n",
    "            variances = []\n",
    "            lls = []\n",
    "            for x_batch, y_batch in test_loader:\n",
    "                preds = self.likelihood(self(x_batch))\n",
    "                mus.append(preds.mean)\n",
    "                variances.append(preds.variance)\n",
    "                lls.append(model.likelihood.log_marginal(y_batch, model(x_batch)))\n",
    "\n",
    "        return torch.cat(mus, dim=-1), torch.cat(variances, dim=-1), torch.cat(lls, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2281d4b0-a6bb-40fd-80d1-3ee1ea33643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepGP2(train_x.shape)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba2567-8472-4558-9e13-693380f51544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Minibatch:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Minibatch:   0%|          | 0/5 [01:48<?, ?it/s, loss=16.6]\u001b[A\n",
      "Minibatch:  20%|██        | 1/5 [01:48<07:13, 108.30s/it, loss=16.6]\u001b[A\n",
      "Minibatch:  20%|██        | 1/5 [03:36<07:13, 108.30s/it, loss=16.9]\u001b[A\n",
      "Minibatch:  40%|████      | 2/5 [03:36<05:24, 108.13s/it, loss=16.9]\u001b[A\n",
      "Minibatch:  40%|████      | 2/5 [05:22<05:24, 108.13s/it, loss=17.5]\u001b[A\n",
      "Minibatch:  60%|██████    | 3/5 [05:22<03:34, 107.38s/it, loss=17.5]\u001b[A\n",
      "Minibatch:  60%|██████    | 3/5 [07:01<03:34, 107.38s/it, loss=16.6]\u001b[A\n",
      "Minibatch:  80%|████████  | 4/5 [07:01<01:44, 104.03s/it, loss=16.6]\u001b[A\n",
      "Minibatch:  80%|████████  | 4/5 [08:37<01:44, 104.03s/it, loss=14.3]\u001b[A\n",
      "Minibatch: 100%|██████████| 5/5 [08:37<00:00, 101.17s/it, loss=14.3]\u001b[A\n",
      "Epoch:  10%|█         | 1/10 [08:37<1:17:41, 517.90s/it]            \u001b[A\n",
      "Minibatch:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Minibatch:   0%|          | 0/5 [01:49<?, ?it/s, loss=16.4]\u001b[A\n",
      "Minibatch:  20%|██        | 1/5 [01:49<07:18, 109.70s/it, loss=16.4]\u001b[A\n",
      "Minibatch:  20%|██        | 1/5 [03:38<07:18, 109.70s/it, loss=15.7]\u001b[A\n",
      "Minibatch:  40%|████      | 2/5 [03:38<05:27, 109.12s/it, loss=15.7]\u001b[A\n",
      "Minibatch:  40%|████      | 2/5 [05:23<05:27, 109.12s/it, loss=15.9]\u001b[A\n",
      "Minibatch:  60%|██████    | 3/5 [05:23<03:34, 107.24s/it, loss=15.9]\u001b[A\n",
      "Minibatch:  60%|██████    | 3/5 [07:10<03:34, 107.24s/it, loss=15]  \u001b[A\n",
      "Minibatch:  80%|████████  | 4/5 [07:10<01:47, 107.06s/it, loss=15]\u001b[A\n",
      "Minibatch:  80%|████████  | 4/5 [08:44<01:47, 107.06s/it, loss=16.1]\u001b[A\n",
      "Minibatch: 100%|██████████| 5/5 [08:44<00:00, 102.39s/it, loss=16.1]\u001b[A\n",
      "Epoch:  20%|██        | 2/10 [17:22<1:09:34, 521.78s/it]            \u001b[A\n",
      "Minibatch:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Minibatch:   0%|          | 0/5 [01:48<?, ?it/s, loss=14.5]\u001b[A\n",
      "Minibatch:  20%|██        | 1/5 [01:48<07:14, 108.70s/it, loss=14.5]\u001b[A\n",
      "Minibatch:  20%|██        | 1/5 [03:35<07:14, 108.70s/it, loss=14.6]\u001b[A\n",
      "Minibatch:  40%|████      | 2/5 [03:35<05:22, 107.47s/it, loss=14.6]\u001b[A\n",
      "Minibatch:  40%|████      | 2/5 [05:15<05:22, 107.47s/it, loss=14.8]\u001b[A\n",
      "Minibatch:  60%|██████    | 3/5 [05:15<03:28, 104.37s/it, loss=14.8]\u001b[A\n",
      "Minibatch:  60%|██████    | 3/5 [06:59<03:28, 104.37s/it, loss=15.6]\u001b[A\n",
      "Minibatch:  80%|████████  | 4/5 [06:59<01:44, 104.18s/it, loss=15.6]\u001b[A"
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "num_epochs = 1 if smoke_test else 10\n",
    "num_samples = 3 if smoke_test else 10\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},\n",
    "], lr=0.01)\n",
    "mll = DeepApproximateMLL(VariationalELBO(model.likelihood, model, train_x.shape[-2]))\n",
    "\n",
    "epochs_iter = tqdm.tqdm(range(num_epochs), desc=\"Epoch\")\n",
    "for i in epochs_iter:\n",
    "    # Within each iteration, we will go over each minibatch of data\n",
    "    minibatch_iter = tqdm.tqdm(train_loader, desc=\"Minibatch\", leave=False)\n",
    "    for x_batch, y_batch in minibatch_iter:\n",
    "        with gpytorch.settings.num_likelihood_samples(num_samples):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = -mll(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            minibatch_iter.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f384e61b-2f26-43a1-8742-c27d9353c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_log_predictive_density(test_y, predicted_mean, predicted_var):\n",
    "    \n",
    "    # Vector of log-predictive density per test point    \n",
    "    lpd = torch.distributions.Normal(predicted_mean, torch.sqrt(predicted_var)).log_prob(test_y)\n",
    "    \n",
    "    # return the average\n",
    "    return -torch.mean(lpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df32b67-61bb-4d7a-ae42-c0317575e246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556be32-4109-4d7b-ad03-31109bedda6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import math\n",
    "\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024)\n",
    "\n",
    "model.eval()\n",
    "predictive_means, predictive_variances, test_lls = model.predict(test_loader)\n",
    "\n",
    "rmse = sqrt_mean_squared_error(test_y, predictive_means)\n",
    "nlpd = negative_log_predictive_density(test_y, predictive_means, predictive_variances)\n",
    "\n",
    "print(f\"RMSE: {rmse.item()}, NLPD: {nlpd.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dd10f7-48a8-4333-a82e-29fb56e4f954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d7f4ad-bd16-446e-8f80-753e72f73065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
