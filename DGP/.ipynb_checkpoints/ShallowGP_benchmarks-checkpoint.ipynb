{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca08450a-8615-4677-b4ca-c011d082ffb8",
   "metadata": {},
   "source": [
    "# Shallow GP benchmarks\n",
    "\n",
    "Shallow GP benchmarks for 'Kernels with Latent Gaussian Processes for Non-stationary Regression' paper.\n",
    "Here we train and evaluate GPs with the following kernels\n",
    "- Squared exponemtial\n",
    "- Squared exponemtial times periodic plus squared exponential (custom kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbd342ae-a6a4-4b0a-be85-bebb2fd186b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%set_env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "import gpytorch\n",
    "from gpytorch.means import ConstantMean, LinearMean\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from gpytorch.variational import VariationalStrategy, CholeskyVariationalDistribution\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.models import ApproximateGP, GP\n",
    "from gpytorch.mlls import VariationalELBO, AddedLossTerm\n",
    "from gpytorch.likelihoods import GaussianLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f03c76c-9930-4b3d-8ddd-38d4da375ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models.deep_gps import DeepGPLayer, DeepGP\n",
    "from gpytorch.mlls import DeepApproximateMLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb6f5f6b-c407-4038-bc03-90e337456f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "from math import floor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc9a884-ea07-4c03-994a-57666c3a59bb",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e502ec-1a8a-4af4-87d8-71dc8565077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "smoke_test = ('CI' in os.environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "703a7fc5-daee-47c5-96a2-06e9d52b2bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('khyber_2000_2010_tp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "063622ad-31ea-4cbb-acd2-413819a8e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if smoke_test:  # this is for running the notebook in our testing framework\n",
    "    X, y = torch.randn(1000, 3), torch.randn(1000)\n",
    "else:\n",
    "    data = torch.Tensor(data_df.values)\n",
    "    X = data[:, :-1]\n",
    "    X = X - X.min(0)[0]\n",
    "    X = 2 * (X / X.max(0)[0]) - 1\n",
    "    y = data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6a5f82b-8688-4dfc-ab81-67f05f0a36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = int(floor(0.8 * len(X)))\n",
    "train_x = X[:train_n, :].contiguous()\n",
    "train_y = y[:train_n].contiguous()\n",
    "\n",
    "test_x = X[train_n:, :].contiguous()\n",
    "test_y = y[train_n:].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "422310fa-e7fb-4906-b09a-3485332495e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    train_x, train_y, test_x, test_y = train_x.cuda(), train_y.cuda(), test_x.cuda(), test_y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b959f1bb-e067-43b2-8604-4e466335fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3ee54b-5641-460d-8ece-59096de41025",
   "metadata": {},
   "source": [
    "## Exact GP class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c0468a3-0e02-4929-a110-56f5578d81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, kernel):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38b0a4a1-ccc4-456f-a174-7218bc85aa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernels\n",
    "SE_kernel = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "custom_kernel = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=4) + gpytorch.kernels.RBFKernel(ard_num_dims=1, active_dims=[0])* gpytorch.kernels.PeriodicKernel(active_dims=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d9914da-2e56-486f-af60-3aa00d3ff89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood, SE_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f19b72-e1d7-45c8-a698-b87f498e8560",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90972e24-d5c2-4ddd-89eb-bc8b8c161093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = 2 if smoke_test else 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "740fb062-fb5a-4e8f-a245-6d2d6baaf29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianLikelihood(\n",
       "  (noise_covar): HomoskedasticNoise(\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2281d4b0-a6bb-40fd-80d1-3ee1ea33643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cb7bf62-1d57-40f3-927c-ab385dfb1f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba2567-8472-4558-9e13-693380f51544",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    '''\n",
    "    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "        i + 1, training_iter, loss.item(),\n",
    "        model.covar_module.base_kernel.lengthscale.item(),\n",
    "        model.likelihood.noise.item()\n",
    "    ))\n",
    "    '''\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744a9bff-a2b2-431a-8bd5-6536ce771075",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556be32-4109-4d7b-ad03-31109bedda6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    trained_pred_dist = likelihood(model(test_x))\n",
    "    predictive_mean = trained_pred_dist.mean\n",
    "\n",
    "rmse =  gpytorch.metrics.mean_squared_error(trained_pred_dist, test_y, squared=False)\n",
    "nlpd = gpytorch.metrics.negative_log_predictive_density(trained_pred_dist, test_y)\n",
    "\n",
    "print(f\"RMSE: {rmse.item()}, NLPD: {nlpd.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
