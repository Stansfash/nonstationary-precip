{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca08450a-8615-4677-b4ca-c011d082ffb8",
   "metadata": {},
   "source": [
    "# Shallow GP benchmarks\n",
    "\n",
    "Shallow GP benchmarks for 'Kernels with Latent Gaussian Processes for Non-stationary Regression' paper.\n",
    "Here we train and evaluate GPs with the following kernels\n",
    "- Squared exponemtial\n",
    "- Squared exponemtial times periodic plus squared exponential (custom kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b98a68-c194-468d-891d-eb1957f6cced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 5, done.\u001b[K\n",
      "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 4 (delta 1), reused 4 (delta 1), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (4/4), 2.36 KiB | 86.00 KiB/s, done.\n",
      "From https://github.com/kenzaxtazi/nonstationary-precip\n",
      "   40a5d26..cb7d1e3  main       -> origin/main\n",
      "Updating 40a5d26..cb7d1e3\n",
      "Fast-forward\n",
      " metrics.py |  48 \u001b[32m+++++++++++++++++++++++\u001b[m\n",
      " sgpr.py    | 128 \u001b[32m+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\n",
      " 2 files changed, 176 insertions(+)\n",
      " create mode 100644 metrics.py\n",
      " create mode 100644 sgpr.py\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbd342ae-a6a4-4b0a-be85-bebb2fd186b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%set_env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "import gpytorch\n",
    "from gpytorch.means import ConstantMean, LinearMean\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from gpytorch.variational import VariationalStrategy, CholeskyVariationalDistribution\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.models import ApproximateGP, GP\n",
    "from gpytorch.mlls import VariationalELBO, AddedLossTerm\n",
    "from gpytorch.likelihoods import GaussianLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f03c76c-9930-4b3d-8ddd-38d4da375ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models.deep_gps import DeepGPLayer, DeepGP\n",
    "from gpytorch.mlls import DeepApproximateMLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb6f5f6b-c407-4038-bc03-90e337456f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "from math import floor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc9a884-ea07-4c03-994a-57666c3a59bb",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16e502ec-1a8a-4af4-87d8-71dc8565077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "smoke_test = ('CI' in os.environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "703a7fc5-daee-47c5-96a2-06e9d52b2bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('khyber_2000_2010_tp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "063622ad-31ea-4cbb-acd2-413819a8e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if smoke_test:  # this is for running the notebook in our testing framework\n",
    "    X, y = torch.randn(1000, 3), torch.randn(1000)\n",
    "else:\n",
    "    data = torch.Tensor(data_df.values)\n",
    "    X = data[:, 1:-1]\n",
    "    X = X - X.min(0)[0]\n",
    "    X = 2 * (X / X.max(0)[0]) - 1\n",
    "    y = data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6a5f82b-8688-4dfc-ab81-67f05f0a36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = int(floor(0.8 * len(X)))\n",
    "train_x = X[:train_n, :].contiguous()\n",
    "train_y = y[:train_n].contiguous()\n",
    "\n",
    "test_x = X[train_n:, :].contiguous()\n",
    "test_y = y[train_n:].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "422310fa-e7fb-4906-b09a-3485332495e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    train_x, train_y, test_x, test_y = train_x.cuda(), train_y.cuda(), test_x.cuda(), test_y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b959f1bb-e067-43b2-8604-4e466335fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3ee54b-5641-460d-8ece-59096de41025",
   "metadata": {},
   "source": [
    "## Exact GP class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c0468a3-0e02-4929-a110-56f5578d81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, kernel):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38b0a4a1-ccc4-456f-a174-7218bc85aa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernels\n",
    "SE_kernel = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "custom_kernel = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=3) + gpytorch.kernels.RBFKernel(ard_num_dims=1, active_dims=[0])* gpytorch.kernels.PeriodicKernel(active_dims=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d9914da-2e56-486f-af60-3aa00d3ff89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood, custom_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f19b72-e1d7-45c8-a698-b87f498e8560",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90972e24-d5c2-4ddd-89eb-bc8b8c161093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = 2 if smoke_test else 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "740fb062-fb5a-4e8f-a245-6d2d6baaf29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianLikelihood(\n",
       "  (noise_covar): HomoskedasticNoise(\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2281d4b0-a6bb-40fd-80d1-3ee1ea33643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5cb7bf62-1d57-40f3-927c-ab385dfb1f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8ba2567-8472-4558-9e13-693380f51544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/50 - Loss: 4.940\n",
      "Iter 2/50 - Loss: 4.590\n",
      "Iter 3/50 - Loss: 4.336\n",
      "Iter 4/50 - Loss: 4.062\n",
      "Iter 5/50 - Loss: 3.662\n",
      "Iter 6/50 - Loss: 3.514\n",
      "Iter 7/50 - Loss: 3.337\n",
      "Iter 8/50 - Loss: 3.138\n",
      "Iter 9/50 - Loss: 2.887\n",
      "Iter 10/50 - Loss: 2.667\n",
      "Iter 11/50 - Loss: 2.562\n",
      "Iter 12/50 - Loss: 2.500\n",
      "Iter 13/50 - Loss: 2.424\n",
      "Iter 14/50 - Loss: 2.317\n",
      "Iter 15/50 - Loss: 2.206\n",
      "Iter 16/50 - Loss: 2.126\n",
      "Iter 17/50 - Loss: 2.079\n",
      "Iter 18/50 - Loss: 1.996\n",
      "Iter 19/50 - Loss: 1.953\n",
      "Iter 20/50 - Loss: 1.880\n",
      "Iter 21/50 - Loss: 1.844\n",
      "Iter 22/50 - Loss: 1.814\n",
      "Iter 23/50 - Loss: 1.793\n",
      "Iter 24/50 - Loss: 1.783\n",
      "Iter 25/50 - Loss: 1.782\n",
      "Iter 26/50 - Loss: 1.776\n",
      "Iter 27/50 - Loss: 1.778\n",
      "Iter 28/50 - Loss: 1.776\n",
      "Iter 29/50 - Loss: 1.771\n",
      "Iter 30/50 - Loss: 1.775\n",
      "Iter 31/50 - Loss: 1.772\n",
      "Iter 32/50 - Loss: 1.771\n",
      "Iter 33/50 - Loss: 1.772\n",
      "Iter 34/50 - Loss: 1.771\n",
      "Iter 35/50 - Loss: 1.772\n",
      "Iter 36/50 - Loss: 1.771\n",
      "Iter 37/50 - Loss: 1.771\n",
      "Iter 38/50 - Loss: 1.773\n",
      "Iter 39/50 - Loss: 1.771\n",
      "Iter 40/50 - Loss: 1.772\n",
      "Iter 41/50 - Loss: 1.772\n",
      "Iter 42/50 - Loss: 1.770\n",
      "Iter 43/50 - Loss: 1.772\n",
      "Iter 44/50 - Loss: 1.775\n",
      "Iter 45/50 - Loss: 1.772\n",
      "Iter 46/50 - Loss: 1.768\n",
      "Iter 47/50 - Loss: 1.775\n",
      "Iter 48/50 - Loss: 1.766\n",
      "Iter 49/50 - Loss: 1.771\n",
      "Iter 50/50 - Loss: 1.771\n"
     ]
    }
   ],
   "source": [
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f'   #lengthscale: %.3f   noise: %.3f' \n",
    "          % (i + 1, training_iter, loss.item(),\n",
    "        #model.covar_module.base_kernel.lengthscale.item(),\n",
    "        #model.likelihood.noise.item()\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744a9bff-a2b2-431a-8bd5-6536ce771075",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8721be42-cd37-4ae9-a250-50307a2f83de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_log_predictive_density(test_y, predicted_mean, predicted_var):\n",
    "    \n",
    "    # Vector of log-predictive density per test point    \n",
    "    lpd = torch.distributions.Normal(predicted_mean, torch.sqrt(predicted_var)).log_prob(test_y)\n",
    "    \n",
    "    # return the average\n",
    "    return -torch.mean(lpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5197d16e-bb2d-4801-9c51-73b3956d900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqrt_mean_squared_error(test_y, predicted_mean):\n",
    "        \n",
    "    return torch.sqrt(torch.mean((test_y - predicted_mean)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2556be32-4109-4d7b-ad03-31109bedda6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.3276002407073975, NLPD: 2.8366599082946777\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    trained_pred_dist = likelihood(model(test_x))\n",
    "    predictive_mean = trained_pred_dist.mean\n",
    "    predictive_variances = trained_pred_dist.variance\n",
    "\n",
    "rmse = sqrt_mean_squared_error(test_y, predictive_mean)\n",
    "nlpd = negative_log_predictive_density(test_y, predictive_mean, predictive_variances)\n",
    "\n",
    "print(f\"RMSE: {rmse.item()}, NLPD: {nlpd.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
